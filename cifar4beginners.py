# -*- coding: utf-8 -*-
"""cifar4beginners.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fVk9V56nghYQSoHD-CyLbeZpMjL0f8YQ
"""

# Commented out IPython magic to ensure Python compatibility.
'''
Code written by Dweep Joshipura
Blog - lightspeedac.blogspot.com
Please read the comments carefully
'''
# Please use the GPU Hardware Accelerator to save time.
# Go to Edit->Notebook Settings->Hardware Accelerator and choose GPU and Save
# Importing keras indirectly
import tensorflow.keras as keras
# Importing kinds of layers
from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,BatchNormalization,Dropout,Flatten
# Importing basic sequential model
from tensorflow.keras.models import Sequential
# Importing 10 class classifying dataset cifar10
from tensorflow.keras.datasets import cifar10
# Importing preprocessing function
from tensorflow.keras.utils import to_categorical
# Ensuring TF 1 is used
# %tensorflow_version 1.x
# Getting data from cifar10
'''
x is the Input
y is the Truth Output for the Input x
x_test is additional testing input
y_test is Truth Output for Input X_test
'''
(x,y),(x_test,y_test) = cifar10.load_data()
# We have 10 classes, namely airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks.
num_classes = 10
# Preprocessing the ground truth
y = to_categorical(y,num_classes)
y_test = to_categorical(y_test,num_classes)

#This model also uses the Sequential api.
model = Sequential(name="My-first-CNN")
'''
We are applying the convolutional operation to the input.
3X3 filters are used (f=3)
padding="same" ensures that the image isn't shrunk (p="same")
We are applying the 'relu' activation talked about in Intro to DL blog
We are applying 32 such filters(small matrices) (nf = 32)
'''
model.add(Conv2D(filters=32,kernel_size=(3,3),padding="same",activation='relu',input_shape=x.shape[1:]))
'''
nf = 64
f = 5
p = "valid"
You may edit and play around to maximize accuracy
'''
model.add(Conv2D(filters=64,kernel_size=(5,5),activation='relu'))
'''
This is another type of layer that simply takes 2-by-2 chunks and selects the Maximum value
The size = 2 is default in Keras
It halves the size and will be referred to as a 'halving' layer
'''
model.add(MaxPooling2D())
'''
The third type of layer is called Batch Normalization
This normalizes the previous layer output
'''
model.add(BatchNormalization())
#nf = 32, f = 3,p = "valid"
model.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))
# Another 'halving' layer
model.add(MaxPooling2D())
# Normalizing layer
model.add(BatchNormalization())
# A dropout layer as talked about in intro to Deep Learning CODE.
model.add(Dropout(0.25))

# We encourage you to play around with parameters like dropout rate and f,p,nf
# nf = 64, f = 3, p = "same" (We will not write these values, we are assuming you understand where they're written)
model.add(Conv2D(filters=64,kernel_size=(3,3),padding="same",activation="relu"))
model.add(Conv2D(filters=128,kernel_size=(7,7),activation='relu',padding="same"))
model.add(MaxPooling2D())
model.add(BatchNormalization())
model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding="same"))
model.add(MaxPooling2D())
model.add(BatchNormalization())
model.add(Dropout(0.25))
#This takes the input and turns it into a vector (group of values)
model.add(Flatten())
# A usual NN layer as talked in DL intro blog
model.add(Dense(512,activation='relu'))
model.add(Dropout(0.5))
# The num_classes has to be there, as this is the last layer. DO NOT CHANGE
# The Softmax function has been talked about in Intro to DL CODE
model.add(Dense(num_classes,activation='softmax'))
# We shall continue using Adaptive Moment Estimation (ADAM) as optimizer
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
# To prevent fluctuations, we will train the whole dataset 50 times, validating with the test set.
model.fit(x=x,y=y,epochs=50,verbose=2, validation_data=(x_test,y_test))
# Evaluating the model on test set
score = model.evaluate(x_test,y_test,verbose=0)
print("The accuracy is "+str(int(score[1]*100))+"%")